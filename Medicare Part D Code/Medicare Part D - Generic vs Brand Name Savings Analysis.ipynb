{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3630b9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEDICARE PART D: GENERIC vs BRAND NAME SAVINGS ANALYSIS\n",
      "================================================================================\n",
      "Analysis Date: 2025-08-17 16:42:34\n",
      "Data Source: CMS Medicare Part D Spending by Drug API\n",
      "API Endpoint: https://data.cms.gov/data-api/v1/dataset/7e0b4365-fd63-4a29-8f5e-e0ac9f66a81b/data\n",
      "Business Question: How much could Medicare save with generic adoption?\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Medicare Part D: Generic vs Brand Name Savings Analysis\n",
    "# Case Study: How much could Medicare save by increasing generic drug adoption?\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"MEDICARE PART D: GENERIC vs BRAND NAME SAVINGS ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"Data Source: CMS Medicare Part D Spending by Drug API\")\n",
    "print(\"API Endpoint: https://data.cms.gov/data-api/v1/dataset/7e0b4365-fd63-4a29-8f5e-e0ac9f66a81b/data\")\n",
    "print(\"Business Question: How much could Medicare save with generic adoption?\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "402bb09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to fetch data\n",
    "\n",
    "def fetch_medicare_part_d_data(limit=5000, offset=0):\n",
    "    \"\"\"\n",
    "    Fetch Medicare Part D data from CMS API\n",
    "    \n",
    "    Parameters:\n",
    "    limit (int): Number of records to fetch (API appears to max at 5000)\n",
    "    offset (int): Starting record number for pagination\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Medicare Part D drug spending data\n",
    "    \"\"\"\n",
    "    \n",
    "    base_url = \"https://data.cms.gov/data-api/v1/dataset/7e0b4365-fd63-4a29-8f5e-e0ac9f66a81b/data\"\n",
    "    \n",
    "    # Try different parameter combinations that might work with this API\n",
    "    params = {\n",
    "        'size': limit,\n",
    "        'offset': offset\n",
    "    }\n",
    "    \n",
    "    # Alternative parameter names to try if the above doesn't work\n",
    "    alt_params = [\n",
    "        {'limit': limit, 'skip': offset},\n",
    "        {'$limit': limit, '$offset': offset},\n",
    "        {'per_page': limit, 'page': offset // limit + 1}\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        print(f\"Fetching Medicare Part D data (limit={limit}, offset={offset})...\")\n",
    "        \n",
    "        # Try main parameters first\n",
    "        response = requests.get(base_url, params=params, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        print(f\"Successfully fetched {len(df)} records\")\n",
    "        \n",
    "        # If we got fewer records than expected, let's check the response headers for pagination info\n",
    "        if len(df) < limit and offset == 0:\n",
    "            print(f\"Response headers (for debugging):\")\n",
    "            for key, value in response.headers.items():\n",
    "                if any(word in key.lower() for word in ['total', 'count', 'page', 'limit']):\n",
    "                    print(f\"      {key}: {value}\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        \n",
    "        # Try alternative parameter combinations\n",
    "        for i, alt_param in enumerate(alt_params):\n",
    "            try:\n",
    "                print(f\"   Trying alternative parameter set {i+1}: {alt_param}\")\n",
    "                response = requests.get(base_url, params=alt_param, timeout=30)\n",
    "                response.raise_for_status()\n",
    "                data = response.json()\n",
    "                df = pd.DataFrame(data)\n",
    "                print(f\"   Alternative method worked! Fetched {len(df)} records\")\n",
    "                return df\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        print(f\"   All parameter combinations failed\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def fetch_all_medicare_data(batch_size=5000, target_records=14309):\n",
    "    \"\"\"Fetch all available Medicare Part D data using proper pagination\"\"\"\n",
    "    \n",
    "    all_data = []\n",
    "    offset = 0\n",
    "    \n",
    "    print(f\"Fetching Medicare Part D data (target: {target_records:,} records)...\")\n",
    "    print(f\"   API appears to limit responses to {batch_size:,} records per request\")\n",
    "    \n",
    "    while True:\n",
    "        batch = fetch_medicare_part_d_data(limit=batch_size, offset=offset)\n",
    "        \n",
    "        if batch.empty:\n",
    "            print(f\"   No more data returned at offset {offset:,}\")\n",
    "            break\n",
    "            \n",
    "        all_data.append(batch)\n",
    "        \n",
    "        # Calculate running total\n",
    "        total_so_far = sum(len(df) for df in all_data)\n",
    "        print(f\"   Batch {len(all_data)}: {len(batch):,} records | Total: {total_so_far:,}\")\n",
    "        \n",
    "        # If we got less than batch_size, we've reached the end\n",
    "        if len(batch) < batch_size:\n",
    "            print(f\"   Reached end of data (received {len(batch):,} < {batch_size:,})\")\n",
    "            break\n",
    "            \n",
    "        # If we've reached our target, we can stop (optional safety check)\n",
    "        if total_so_far >= target_records:\n",
    "            print(f\"   Reached target of {target_records:,} records\")\n",
    "            break\n",
    "        \n",
    "        # Increment offset for next batch\n",
    "        offset += len(batch)\n",
    "        \n",
    "        # Add a small delay to be respectful to the API\n",
    "        import time\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    if all_data:\n",
    "        combined_df = pd.concat(all_data, ignore_index=True)\n",
    "        expected_vs_actual = f\"Expected: {target_records:,} | Actual: {len(combined_df):,}\"\n",
    "        \n",
    "        if len(combined_df) == target_records:\n",
    "            print(f\"SUCCESS: Fetched all {len(combined_df):,} records!\")\n",
    "        elif len(combined_df) < target_records:\n",
    "            print(f\"PARTIAL: Fetched {len(combined_df):,} of {target_records:,} records\")\n",
    "            print(f\"   Possible reasons: API limits, data changes, or network issues\")\n",
    "        else:\n",
    "            print(f\"UNEXPECTED: Fetched {len(combined_df):,} records (more than expected {target_records:,})\")\n",
    "        \n",
    "        print(f\"   {expected_vs_actual}\")\n",
    "        return combined_df\n",
    "    else:\n",
    "        print(\"No data retrieved from any batch\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5149ee30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STEP 1: Extracting All Medicare Part D Data from CMS API\n",
      "Fetching Medicare Part D data (target: 14,309 records)...\n",
      "   API appears to limit responses to 5,000 records per request\n",
      "Fetching Medicare Part D data (limit=5000, offset=0)...\n",
      "Successfully fetched 5000 records\n",
      "   Batch 1: 5,000 records | Total: 5,000\n",
      "Fetching Medicare Part D data (limit=5000, offset=5000)...\n",
      "Successfully fetched 5000 records\n",
      "   Batch 2: 5,000 records | Total: 10,000\n",
      "Fetching Medicare Part D data (limit=5000, offset=10000)...\n",
      "Successfully fetched 4309 records\n",
      "   Batch 3: 4,309 records | Total: 14,309\n",
      "   Reached end of data (received 4,309 < 5,000)\n",
      "SUCCESS: Fetched all 14,309 records!\n",
      "   Expected: 14,309 | Actual: 14,309\n",
      "\n",
      "Dataset Overview:\n",
      "   Total Drug Records: 14,309\n",
      "   Columns: ['Brnd_Name', 'Gnrc_Name', 'Tot_Mftr', 'Mftr_Name', 'Tot_Spndng_2019', 'Tot_Dsg_Unts_2019', 'Tot_Clms_2019', 'Tot_Benes_2019', 'Avg_Spnd_Per_Dsg_Unt_Wghtd_2019', 'Avg_Spnd_Per_Clm_2019', 'Avg_Spnd_Per_Bene_2019', 'Outlier_Flag_2019', 'Tot_Spndng_2020', 'Tot_Dsg_Unts_2020', 'Tot_Clms_2020', 'Tot_Benes_2020', 'Avg_Spnd_Per_Dsg_Unt_Wghtd_2020', 'Avg_Spnd_Per_Clm_2020', 'Avg_Spnd_Per_Bene_2020', 'Outlier_Flag_2020', 'Tot_Spndng_2021', 'Tot_Dsg_Unts_2021', 'Tot_Clms_2021', 'Tot_Benes_2021', 'Avg_Spnd_Per_Dsg_Unt_Wghtd_2021', 'Avg_Spnd_Per_Clm_2021', 'Avg_Spnd_Per_Bene_2021', 'Outlier_Flag_2021', 'Tot_Spndng_2022', 'Tot_Dsg_Unts_2022', 'Tot_Clms_2022', 'Tot_Benes_2022', 'Avg_Spnd_Per_Dsg_Unt_Wghtd_2022', 'Avg_Spnd_Per_Clm_2022', 'Avg_Spnd_Per_Bene_2022', 'Outlier_Flag_2022', 'Tot_Spndng_2023', 'Tot_Dsg_Unts_2023', 'Tot_Clms_2023', 'Tot_Benes_2023', 'Avg_Spnd_Per_Dsg_Unt_Wghtd_2023', 'Avg_Spnd_Per_Clm_2023', 'Avg_Spnd_Per_Bene_2023', 'Outlier_Flag_2023', 'Chg_Avg_Spnd_Per_Dsg_Unt_22_23', 'CAGR_Avg_Spnd_Per_Dsg_Unt_19_23']\n",
      "   Memory Usage: 40.32 MB\n",
      "\n",
      "Sample Data (First 3 Records):\n",
      "                       Brnd_Name             Gnrc_Name Tot_Mftr        Mftr_Name Tot_Spndng_2019 Tot_Dsg_Unts_2019 Tot_Clms_2019 Tot_Benes_2019 Avg_Spnd_Per_Dsg_Unt_Wghtd_2019 Avg_Spnd_Per_Clm_2019 Avg_Spnd_Per_Bene_2019 Outlier_Flag_2019 Tot_Spndng_2020 Tot_Dsg_Unts_2020 Tot_Clms_2020 Tot_Benes_2020 Avg_Spnd_Per_Dsg_Unt_Wghtd_2020 Avg_Spnd_Per_Clm_2020 Avg_Spnd_Per_Bene_2020 Outlier_Flag_2020 Tot_Spndng_2021 Tot_Dsg_Unts_2021 Tot_Clms_2021 Tot_Benes_2021 Avg_Spnd_Per_Dsg_Unt_Wghtd_2021 Avg_Spnd_Per_Clm_2021 Avg_Spnd_Per_Bene_2021 Outlier_Flag_2021 Tot_Spndng_2022 Tot_Dsg_Unts_2022 Tot_Clms_2022 Tot_Benes_2022 Avg_Spnd_Per_Dsg_Unt_Wghtd_2022 Avg_Spnd_Per_Clm_2022 Avg_Spnd_Per_Bene_2022 Outlier_Flag_2022 Tot_Spndng_2023 Tot_Dsg_Unts_2023 Tot_Clms_2023 Tot_Benes_2023 Avg_Spnd_Per_Dsg_Unt_Wghtd_2023 Avg_Spnd_Per_Clm_2023 Avg_Spnd_Per_Bene_2023 Outlier_Flag_2023 Chg_Avg_Spnd_Per_Dsg_Unt_22_23 CAGR_Avg_Spnd_Per_Dsg_Unt_19_23\n",
      "0       1st Tier Unifine Pentips  Pen Needle, Diabetic        1          Overall       139201.68            642471          5392           1878                    0.2167879244          25.816335312           74.122300319                 0       118923.24            547006          4457           1595                     0.217701046          26.682351357           74.560025078                 0       102280.76            459384          3708           1313                    0.2230012539          27.583807983           77.898522468                 0        70039.61            310304          2501           1147                     0.225873987          28.004642143           61.063304272                 0        44355.04            195672          1613            699                    0.2271618646          27.498474892           63.454992847                 0                   0.0057017529                    0.0117543595\n",
      "1       1st Tier Unifine Pentips  Pen Needle, Diabetic        1  Owen Mumford Us       139201.68            642471          5392           1878                    0.2167879244          25.816335312           74.122300319                 0       118923.24            547006          4457           1595                     0.217701046          26.682351357           74.560025078                 0       102280.76            459384          3708           1313                    0.2230012539          27.583807983           77.898522468                 0        70039.61            310304          2501           1147                     0.225873987          28.004642143           61.063304272                 0        44355.04            195672          1613            699                    0.2271618646          27.498474892           63.454992847                 0                   0.0057017529                    0.0117543595\n",
      "2  1st Tier Unifine Pentips Plus  Pen Needle, Diabetic        1          Overall       343031.42           1830596         14581           5319                    0.1873888035          23.525918661           64.491712728                 0       210217.15           1046616          8408           3905                     0.200851195          25.002039724           53.832816901                 0       131927.33            566872          4564           1766                    0.2328115409          28.906075811           74.704037373                 0       114601.54            486206          3846           1474                    0.2357078344          29.797592304           77.748670285                 0        97951.18            406617          3269           1267                    0.2409322287          29.963652493           77.309534333                 0                   0.0221647035                    0.0648484791\n"
     ]
    }
   ],
   "source": [
    "# Extract Data from CMS API\n",
    "\n",
    "print(\"\\nSTEP 1: Extracting All Medicare Part D Data from CMS API\")\n",
    "df = fetch_all_medicare_data(batch_size=5000, target_records=14309)\n",
    "\n",
    "# Display basic info about the dataset\n",
    "if not df.empty:\n",
    "    print(f\"\\nDataset Overview:\")\n",
    "    print(f\"   Total Drug Records: {len(df):,}\")\n",
    "    print(f\"   Columns: {list(df.columns)}\")\n",
    "    print(f\"   Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Show sample data\n",
    "    print(f\"\\nSample Data (First 3 Records):\")\n",
    "    print(df.head(3).to_string())\n",
    "else:\n",
    "    print(\"No data retrieved. Please check API connection.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e062ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning data and setting up SQL database...\n",
      "SQL database created with 14,309 records\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Clean Data and Load into SQL\n",
    "def clean_data_for_sql(df):\n",
    "    \"\"\"Clean data and load into SQL database\"\"\"\n",
    "    \n",
    "    if df.empty:\n",
    "        return None\n",
    "    \n",
    "    print(\"Cleaning data and setting up SQL database...\")\n",
    "    clean_df = df.copy()\n",
    "    \n",
    "    # Column mapping\n",
    "    column_mapping = {\n",
    "        'Brnd_Name': 'brand_name',\n",
    "        'Gnrc_Name': 'generic_name',\n",
    "        'Tot_Spndng_2023': 'total_spending_2023',\n",
    "        'Tot_Clms_2023': 'total_claims_2023',\n",
    "        'Tot_Benes_2023': 'total_beneficiaries_2023',\n",
    "        'Avg_Spnd_Per_Clm_2023': 'avg_spending_per_claim_2023',\n",
    "        'Avg_Spnd_Per_Dsg_Unt_Wghtd_2023': 'avg_spending_per_unit_2023',\n",
    "        'Mftr_Name': 'manufacturer'\n",
    "    }\n",
    "    \n",
    "    clean_df = clean_df.rename(columns=column_mapping)\n",
    "    \n",
    "    # Clean names and classify drug type\n",
    "    clean_df['brand_name'] = clean_df['brand_name'].astype(str).str.strip().str.upper()\n",
    "    clean_df['generic_name'] = clean_df['generic_name'].astype(str).str.strip().str.upper()\n",
    "    clean_df['drug_type'] = clean_df.apply(lambda row: 'Generic' if row['brand_name'] == row['generic_name'] else 'Brand', axis=1)\n",
    "    \n",
    "    # Convert numeric columns\n",
    "    numeric_columns = ['total_spending_2023', 'total_claims_2023', 'total_beneficiaries_2023',\n",
    "                      'avg_spending_per_claim_2023', 'avg_spending_per_unit_2023']\n",
    "    \n",
    "    for col in numeric_columns:\n",
    "        if col in clean_df.columns:\n",
    "            clean_df[col] = pd.to_numeric(clean_df[col].astype(str).str.replace(r'[$,]', '', regex=True), errors='coerce')\n",
    "    \n",
    "    # Remove rows with missing critical data\n",
    "    clean_df = clean_df.dropna(subset=['brand_name', 'generic_name'])\n",
    "    \n",
    "    # Create SQL database\n",
    "    conn = sqlite3.connect(':memory:')\n",
    "    clean_df.to_sql('medicare_drugs', conn, if_exists='replace', index=False)\n",
    "    \n",
    "    # Create indexes\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"CREATE INDEX idx_drug_type ON medicare_drugs(drug_type)\")\n",
    "    cursor.execute(\"CREATE INDEX idx_generic_name ON medicare_drugs(generic_name)\")\n",
    "    cursor.execute(\"CREATE INDEX idx_brand_name ON medicare_drugs(brand_name)\")\n",
    "    \n",
    "    print(f\"SQL database created with {len(clean_df):,} records\")\n",
    "    return conn\n",
    "\n",
    "# Clean data and create SQL database\n",
    "sql_conn = clean_data_for_sql(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99d49b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: SQL Analysis Functions\n",
    "def execute_sql_to_dataframe(conn, query, description=\"\"):\n",
    "    \"\"\"Execute SQL and return DataFrame\"\"\"\n",
    "    if description:\n",
    "        print(f\"\\n{description}\")\n",
    "    \n",
    "    try:\n",
    "        result_df = pd.read_sql_query(query, conn)\n",
    "        print(f\"Query executed successfully. Returned {len(result_df)} rows.\")\n",
    "        return result_df\n",
    "    except Exception as e:\n",
    "        print(f\"SQL Error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def export_sql_result(conn, query, filename_prefix, description=\"\"):\n",
    "    \"\"\"Execute SQL query and export to CSV\"\"\"\n",
    "    result_df = execute_sql_to_dataframe(conn, query, description)\n",
    "    \n",
    "    if not result_df.empty:\n",
    "        filename = f\"powerbi_{filename_prefix}.csv\"\n",
    "        result_df.to_csv(filename, index=False)\n",
    "        print(f\"Exported: {filename} ({len(result_df):,} rows)\")\n",
    "        return filename, result_df\n",
    "    \n",
    "    return None, pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c78e8581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PowerBI datasets using SQL...\n",
      "\n",
      "Creating main drug facts table\n",
      "Query executed successfully. Returned 14309 rows.\n",
      "Exported: powerbi_main_drug_facts.csv (14,309 rows)\n",
      "\n",
      "Creating generic vs brand summary\n",
      "Query executed successfully. Returned 2 rows.\n",
      "Exported: powerbi_generic_vs_brand_summary.csv (2 rows)\n",
      "\n",
      "Creating savings opportunities table\n",
      "Query executed successfully. Returned 322 rows.\n",
      "Exported: powerbi_savings_opportunities.csv (322 rows)\n",
      "\n",
      "Creating top opportunities with impact categories\n",
      "Query executed successfully. Returned 50 rows.\n",
      "Exported: powerbi_top_opportunities.csv (50 rows)\n",
      "\n",
      "Creating manufacturer analysis\n",
      "Query executed successfully. Returned 597 rows.\n",
      "Exported: powerbi_manufacturer_analysis.csv (597 rows)\n",
      "\n",
      "SUMMARY:\n",
      "Generated 5 PowerBI-ready datasets:\n",
      "  - powerbi_main_drug_facts.csv\n",
      "  - powerbi_generic_vs_brand_summary.csv\n",
      "  - powerbi_savings_opportunities.csv\n",
      "  - powerbi_top_opportunities.csv\n",
      "  - powerbi_manufacturer_analysis.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Create All PowerBI Datasets Using SQL\n",
    "def create_all_powerbi_datasets_sql(conn):\n",
    "    \"\"\"Create all PowerBI datasets using SQL queries\"\"\"\n",
    "    \n",
    "    exported_files = []\n",
    "    \n",
    "    print(\"Creating PowerBI datasets using SQL...\")\n",
    "    \n",
    "    # 1. Main Drug Facts\n",
    "    main_facts_sql = \"\"\"\n",
    "    SELECT \n",
    "        brand_name,\n",
    "        generic_name,\n",
    "        drug_type,\n",
    "        manufacturer,\n",
    "        total_spending_2023,\n",
    "        total_claims_2023,\n",
    "        total_beneficiaries_2023,\n",
    "        avg_spending_per_claim_2023,\n",
    "        avg_spending_per_unit_2023,\n",
    "        CASE \n",
    "            WHEN total_beneficiaries_2023 > 0 \n",
    "            THEN total_spending_2023 / total_beneficiaries_2023 \n",
    "            ELSE NULL \n",
    "        END as cost_per_beneficiary_2023,\n",
    "        CASE \n",
    "            WHEN total_beneficiaries_2023 > 0 \n",
    "            THEN total_claims_2023 / total_beneficiaries_2023 \n",
    "            ELSE NULL \n",
    "        END as claims_per_beneficiary_2023\n",
    "    FROM medicare_drugs\n",
    "    WHERE brand_name IS NOT NULL \n",
    "    AND generic_name IS NOT NULL\n",
    "    \"\"\"\n",
    "    \n",
    "    filename, df = export_sql_result(conn, main_facts_sql, \"main_drug_facts\", \"Creating main drug facts table\")\n",
    "    if filename:\n",
    "        exported_files.append(filename)\n",
    "    \n",
    "    # 2. Generic vs Brand Summary\n",
    "    summary_sql = \"\"\"\n",
    "    SELECT \n",
    "        drug_type,\n",
    "        COUNT(*) as drug_count,\n",
    "        ROUND(100.0 * COUNT(*) / (SELECT COUNT(*) FROM medicare_drugs), 2) as percentage_of_drugs,\n",
    "        COALESCE(SUM(total_spending_2023), 0) as total_spending,\n",
    "        COALESCE(SUM(total_claims_2023), 0) as total_claims,\n",
    "        COALESCE(SUM(total_beneficiaries_2023), 0) as total_beneficiaries,\n",
    "        COALESCE(AVG(avg_spending_per_claim_2023), 0) as avg_cost_per_claim,\n",
    "        COALESCE(AVG(avg_spending_per_unit_2023), 0) as avg_cost_per_unit,\n",
    "        ROUND(100.0 * SUM(total_spending_2023) / (SELECT SUM(total_spending_2023) FROM medicare_drugs), 2) as percentage_of_spending\n",
    "    FROM medicare_drugs\n",
    "    WHERE drug_type IS NOT NULL\n",
    "    GROUP BY drug_type\n",
    "    ORDER BY total_spending DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    filename, df = export_sql_result(conn, summary_sql, \"generic_vs_brand_summary\", \"Creating generic vs brand summary\")\n",
    "    if filename:\n",
    "        exported_files.append(filename)\n",
    "    \n",
    "    # 3. Savings Opportunities (THE MAIN ONE)\n",
    "    savings_sql = \"\"\"\n",
    "    WITH drug_comparison AS (\n",
    "        SELECT \n",
    "            generic_name,\n",
    "            MAX(CASE WHEN drug_type = 'Brand' THEN avg_spending_per_claim_2023 END) as brand_cost_per_claim,\n",
    "            MAX(CASE WHEN drug_type = 'Generic' THEN avg_spending_per_claim_2023 END) as generic_cost_per_claim,\n",
    "            MAX(CASE WHEN drug_type = 'Brand' THEN total_claims_2023 END) as brand_claims,\n",
    "            MAX(CASE WHEN drug_type = 'Generic' THEN total_claims_2023 END) as generic_claims,\n",
    "            MAX(CASE WHEN drug_type = 'Brand' THEN total_spending_2023 END) as current_brand_spending,\n",
    "            MAX(CASE WHEN drug_type = 'Brand' THEN total_beneficiaries_2023 END) as brand_beneficiaries\n",
    "        FROM medicare_drugs\n",
    "        WHERE drug_type IS NOT NULL \n",
    "        AND avg_spending_per_claim_2023 IS NOT NULL\n",
    "        AND total_claims_2023 IS NOT NULL\n",
    "        GROUP BY generic_name\n",
    "        HAVING COUNT(DISTINCT drug_type) = 2\n",
    "    )\n",
    "    SELECT \n",
    "        generic_name,\n",
    "        ROUND(brand_cost_per_claim, 2) as brand_cost_per_claim,\n",
    "        ROUND(generic_cost_per_claim, 2) as generic_cost_per_claim,\n",
    "        ROUND(brand_cost_per_claim - generic_cost_per_claim, 2) as savings_per_claim,\n",
    "        ROUND(100.0 * (brand_cost_per_claim - generic_cost_per_claim) / brand_cost_per_claim, 2) as percent_savings,\n",
    "        brand_claims,\n",
    "        generic_claims,\n",
    "        brand_beneficiaries,\n",
    "        ROUND(current_brand_spending, 0) as current_brand_spending,\n",
    "        ROUND(brand_claims * (brand_cost_per_claim - generic_cost_per_claim), 0) as total_potential_savings,\n",
    "        ROUND(100.0 * generic_claims / (brand_claims + generic_claims), 2) as market_share_generic\n",
    "    FROM drug_comparison\n",
    "    WHERE brand_cost_per_claim > generic_cost_per_claim\n",
    "    AND brand_cost_per_claim > 0\n",
    "    AND generic_cost_per_claim > 0\n",
    "    ORDER BY total_potential_savings DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    filename, savings_df = export_sql_result(conn, savings_sql, \"savings_opportunities\", \"Creating savings opportunities table\")\n",
    "    if filename:\n",
    "        exported_files.append(filename)\n",
    "    \n",
    "    # 4. Top Opportunities with Impact Categories\n",
    "    if not savings_df.empty:\n",
    "        top_opportunities_sql = f\"\"\"\n",
    "        WITH ranked_opportunities AS (\n",
    "            {savings_sql.replace('ORDER BY total_potential_savings DESC', '')}\n",
    "        ),\n",
    "        top_50 AS (\n",
    "            SELECT *,\n",
    "            CASE \n",
    "                WHEN total_potential_savings >= 1000000000 THEN 'Critical Impact'\n",
    "                WHEN total_potential_savings >= 400000000 THEN 'High Impact'\n",
    "                WHEN total_potential_savings >= 50000000 THEN 'Medium Impact'\n",
    "                ELSE 'Low Impact'\n",
    "            END as impact_category\n",
    "            FROM ranked_opportunities\n",
    "            ORDER BY total_potential_savings DESC\n",
    "            LIMIT 50\n",
    "        )\n",
    "        SELECT * FROM top_50\n",
    "        \"\"\"\n",
    "        \n",
    "        filename, df = export_sql_result(conn, top_opportunities_sql, \"top_opportunities\", \"Creating top opportunities with impact categories\")\n",
    "        if filename:\n",
    "            exported_files.append(filename)\n",
    "    \n",
    "    # 5. Manufacturer Analysis\n",
    "    manufacturer_sql = \"\"\"\n",
    "    SELECT \n",
    "        manufacturer,\n",
    "        drug_type,\n",
    "        COUNT(*) as drug_count,\n",
    "        ROUND(AVG(avg_spending_per_claim_2023), 2) as avg_cost_per_claim,\n",
    "        ROUND(SUM(total_spending_2023), 0) as total_spending,\n",
    "        ROUND(SUM(total_claims_2023), 0) as total_claims,\n",
    "        ROUND(SUM(total_beneficiaries_2023), 0) as total_beneficiaries\n",
    "    FROM medicare_drugs\n",
    "    WHERE manufacturer IS NOT NULL \n",
    "    AND drug_type IS NOT NULL\n",
    "    AND avg_spending_per_claim_2023 IS NOT NULL\n",
    "    AND total_spending_2023 IS NOT NULL\n",
    "    GROUP BY manufacturer, drug_type\n",
    "    HAVING COUNT(*) >= 3\n",
    "    ORDER BY total_spending DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    filename, df = export_sql_result(conn, manufacturer_sql, \"manufacturer_analysis\", \"Creating manufacturer analysis\")\n",
    "    if filename:\n",
    "        exported_files.append(filename)\n",
    "    \n",
    "    return exported_files\n",
    "\n",
    "# Generate all datasets\n",
    "if sql_conn:\n",
    "    exported_files = create_all_powerbi_datasets_sql(sql_conn)\n",
    "    \n",
    "    print(f\"\\nSUMMARY:\")\n",
    "    print(f\"Generated {len(exported_files)} PowerBI-ready datasets:\")\n",
    "    for file in exported_files:\n",
    "        print(f\"  - {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8608a019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating executive summary statistics\n",
      "Query executed successfully. Returned 1 rows.\n",
      "\n",
      "EXECUTIVE SUMMARY:\n",
      "  Drugs with savings potential: 322.0\n",
      "  Total brand claims: 46,115,718.0\n",
      "  Current brand spending: $17,175,111,432.0\n",
      "  Cost if all generic: $35,316,483,211.0\n",
      "  TOTAL POTENTIAL SAVINGS: $99,868,022,524.0\n",
      "  Percent savings potential: 581.5%\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Generate Summary Statistics\n",
    "def generate_summary_stats(conn):\n",
    "    \"\"\"Generate the key summary statistics\"\"\"\n",
    "    \n",
    "    summary_query = \"\"\"\n",
    "    WITH drug_comparison AS (\n",
    "        SELECT \n",
    "            generic_name,\n",
    "            MAX(CASE WHEN drug_type = 'Brand' THEN avg_spending_per_claim_2023 END) as brand_cost_per_claim,\n",
    "            MAX(CASE WHEN drug_type = 'Generic' THEN avg_spending_per_claim_2023 END) as generic_cost_per_claim,\n",
    "            MAX(CASE WHEN drug_type = 'Brand' THEN total_claims_2023 END) as brand_claims,\n",
    "            MAX(CASE WHEN drug_type = 'Brand' THEN total_spending_2023 END) as brand_spending\n",
    "        FROM medicare_drugs\n",
    "        WHERE drug_type IS NOT NULL \n",
    "        AND avg_spending_per_claim_2023 IS NOT NULL\n",
    "        AND total_claims_2023 IS NOT NULL\n",
    "        GROUP BY generic_name\n",
    "        HAVING COUNT(DISTINCT drug_type) = 2\n",
    "    )\n",
    "    SELECT \n",
    "        COUNT(*) as drugs_with_savings_potential,\n",
    "        SUM(brand_claims) as total_brand_claims,\n",
    "        ROUND(SUM(brand_spending), 0) as total_current_brand_spending,\n",
    "        ROUND(SUM(brand_claims * generic_cost_per_claim), 0) as cost_if_all_generic,\n",
    "        ROUND(SUM(brand_claims * (brand_cost_per_claim - generic_cost_per_claim)), 0) as total_potential_savings,\n",
    "        ROUND(100.0 * SUM(brand_claims * (brand_cost_per_claim - generic_cost_per_claim)) / SUM(brand_spending), 2) as percent_savings_potential\n",
    "    FROM drug_comparison\n",
    "    WHERE brand_cost_per_claim > generic_cost_per_claim\n",
    "    AND brand_cost_per_claim > 0\n",
    "    AND generic_cost_per_claim > 0\n",
    "    \"\"\"\n",
    "    \n",
    "    summary_df = execute_sql_to_dataframe(conn, summary_query, \"Generating executive summary statistics\")\n",
    "    \n",
    "    if not summary_df.empty:\n",
    "        stats = summary_df.iloc[0]\n",
    "        print(f\"\\nEXECUTIVE SUMMARY:\")\n",
    "        print(f\"  Drugs with savings potential: {stats['drugs_with_savings_potential']:,}\")\n",
    "        print(f\"  Total brand claims: {stats['total_brand_claims']:,}\")\n",
    "        print(f\"  Current brand spending: ${stats['total_current_brand_spending']:,}\")\n",
    "        print(f\"  Cost if all generic: ${stats['cost_if_all_generic']:,}\")\n",
    "        print(f\"  TOTAL POTENTIAL SAVINGS: ${stats['total_potential_savings']:,}\")\n",
    "        print(f\"  Percent savings potential: {stats['percent_savings_potential']:.1f}%\")\n",
    "\n",
    "if sql_conn:\n",
    "    generate_summary_stats(sql_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb85df86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection closed\n",
      "\n",
      "ANALYSIS COMPLETE!\n",
      "All PowerBI datasets generated using consistent SQL approach\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Cleanup\n",
    "if sql_conn:\n",
    "    sql_conn.close()\n",
    "    print(\"Database connection closed\")\n",
    "\n",
    "print(\"\\nANALYSIS COMPLETE!\")\n",
    "print(\"All PowerBI datasets generated using consistent SQL approach\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
